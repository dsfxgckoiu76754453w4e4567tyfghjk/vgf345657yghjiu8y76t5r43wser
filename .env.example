# Environment Configuration
ENVIRONMENT=dev  # dev, test, prod

# Application
APP_NAME=Shia Islamic Chatbot
APP_VERSION=1.0.0
DEBUG=true
API_HOST=0.0.0.0
API_PORT=8000

# Database (PostgreSQL) - Separate Parameters (Recommended)
# Note: Using port 5433 to avoid conflicts with system PostgreSQL
DATABASE_HOST=localhost
DATABASE_PORT=5433
DATABASE_USER=postgres
DATABASE_PASSWORD=postgres
DATABASE_NAME=shia_chatbot
DATABASE_DRIVER=postgresql+asyncpg
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=10

# Note: Database URL is automatically constructed from the individual parameters above
# Do NOT set DATABASE_URL environment variable as it will override the individual parameters

# Redis
REDIS_URL=redis://localhost:6379/0
REDIS_CACHE_DB=1
REDIS_QUEUE_DB=2

# Qdrant (Vector Database)
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
QDRANT_COLLECTION_NAME=islamic_knowledge

# JWT & Security
JWT_SECRET_KEY=your-secret-key-change-in-production
JWT_ALGORITHM=HS256
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30
JWT_REFRESH_TOKEN_EXPIRE_DAYS=7

# Google OAuth
GOOGLE_CLIENT_ID=your-google-client-id
GOOGLE_CLIENT_SECRET=your-google-client-secret
GOOGLE_REDIRECT_URI=http://localhost:8000/auth/google/callback

# LLM Providers - Legacy (Optional if using OpenRouter)
OPENAI_API_KEY=your-openai-api-key
OPENAI_ORG_ID=

# LLM Providers - Anthropic
ANTHROPIC_API_KEY=your-anthropic-api-key

# LLM Providers - Google
GOOGLE_API_KEY=your-google-api-key
GOOGLE_PROJECT_ID=your-google-project-id
GOOGLE_LOCATION=us-central1

# LLM Providers - Cohere
COHERE_API_KEY=your-cohere-api-key

# OpenRouter - Unified LLM API (RECOMMENDED)
# Sign up at: https://openrouter.ai
# Get API key from: https://openrouter.ai/keys
# Supports 100+ models from OpenAI, Anthropic, Google, Meta, Mistral, and more
OPENROUTER_API_KEY=sk-or-v1-...
OPENROUTER_APP_NAME=WisQu Islamic Chatbot
OPENROUTER_APP_URL=https://wisqu.com

# LLM Configuration (Used by LangGraph service)
LLM_PROVIDER=openrouter  # openrouter (recommended), openai, anthropic
LLM_MODEL=anthropic/claude-3.5-sonnet  # or openai/gpt-4-turbo, google/gemini-pro-1.5, etc.
LLM_TEMPERATURE=0.7  # 0.0-1.0 (0=deterministic, 1=creative)
LLM_MAX_TOKENS=4096

# Embeddings
EMBEDDING_PROVIDER=gemini  # gemini, cohere, openrouter
EMBEDDING_MODEL=gemini-embedding-001
# For OpenRouter embeddings, use models like: openai/text-embedding-3-large
EMBEDDING_DIMENSION=3072

# Web Search
WEB_SEARCH_ENABLED=true
WEB_SEARCH_PROVIDER=tavily  # tavily, serper, openrouter

# Traditional Search APIs:
# Tavily API (Recommended for LLM applications)
# Sign up at: https://tavily.com
TAVILY_API_KEY=tvly-...
# Serper API (Google Search)
# Sign up at: https://serper.dev
SERPER_API_KEY=...

# OpenRouter Search (Uses search-enabled LLM models)
# When WEB_SEARCH_PROVIDER=openrouter, uses models with built-in web search:
WEB_SEARCH_MODEL=perplexity/sonar-deep-research
# Alternative models:
# - perplexity/sonar-deep-research (deep research with citations, recommended)
# - openai/gpt-4o-search-preview (GPT-4 with search, high quality)
# - openai/gpt-4o-mini-search-preview (faster, cheaper alternative)
WEB_SEARCH_TEMPERATURE=0.3  # Lower for more factual responses
WEB_SEARCH_MAX_TOKENS=4096

# Reranker
RERANKER_PROVIDER=cohere  # cohere, vertex
RERANKER_MODEL=rerank-3.5

# ASR (Speech-to-Text)
ASR_PROVIDER=google  # google, whisper
GOOGLE_SPEECH_API_KEY=your-google-speech-api-key

# Chonkie (Chunking)
CHUNKING_STRATEGY=semantic  # semantic, token, sentence, adaptive
CHUNK_SIZE=512
CHUNK_OVERLAP=50

# mem0 (Memory)
MEM0_ENABLED=true
MEM0_COMPRESSION_ENABLED=true

# NeMo Guardrails
GUARDRAILS_ENABLED=true
GUARDRAILS_LLM_PROVIDER=openai
GUARDRAILS_LLM_MODEL=gpt-4o-mini

# Logging & Observability (Standard v2.0)
# Log Level: Controls verbosity of logs
LOG_LEVEL=DEBUG  # DEBUG | INFO | WARNING | ERROR (default: DEBUG in dev, WARNING in prod)

# Log Format: Output format for logs
LOG_FORMAT=colored  # colored | json (default: colored in dev, json in test/prod)

# Log Timestamp: Which timestamps to display
LOG_TIMESTAMP=both  # utc | ir | both (default: both)
# - utc: Only UTC timestamp
# - ir: Only Iranian/Jalali timestamp
# - both: Both UTC and Iranian timestamps

# Log Timestamp Precision: Microsecond precision
LOG_TIMESTAMP_PRECISION=6  # 3 (milliseconds) | 6 (microseconds) (default: 6)

# Log Color: ANSI color output control
LOG_COLOR=auto  # auto | true | false (default: auto)
# - auto: Auto-detect based on TTY, Docker, etc.
# - true: Force colors on
# - false: Force colors off
# Alternative: Set NO_COLOR=1 to disable colors (https://no-color.org/)

# Langfuse (LLM Observability) - Two modes available:
#
# MODE 1: Langfuse Cloud (RECOMMENDED for production)
# Sign up at: https://cloud.langfuse.com (Free tier available)
# Get your keys from: Project Settings > API Keys
LANGFUSE_ENABLED=true
LANGFUSE_PUBLIC_KEY=pk-lf-...  # Get from Langfuse Cloud
LANGFUSE_SECRET_KEY=sk-lf-...  # Get from Langfuse Cloud
LANGFUSE_HOST=https://cloud.langfuse.com  # EU region
# LANGFUSE_HOST=https://us.cloud.langfuse.com  # US region

# MODE 2: Self-hosted Langfuse (requires ClickHouse, MinIO, Redis)
# Uncomment services in docker-compose.yml and see docs/LANGFUSE_SETUP.md
# LANGFUSE_HOST=http://localhost:3001  # Self-hosted URL

# Rate Limiting (requests per minute)
RATE_LIMIT_ANONYMOUS=5
RATE_LIMIT_FREE=10
RATE_LIMIT_PREMIUM=50
RATE_LIMIT_UNLIMITED=1000
RATE_LIMIT_TEST=10000

# CORS
CORS_ORIGINS=http://localhost:3000,http://localhost:8000
CORS_ALLOW_CREDENTIALS=true

# External API
EXTERNAL_API_ENABLED=true
EXTERNAL_API_DEFAULT_RATE_LIMIT=100

# Ahkam Tool Configuration
AHKAM_CACHE_TTL_HOURS=24
AHKAM_FETCH_TIMEOUT_SECONDS=30
AHKAM_MAX_RETRIES=3

# HuggingFace Backup
HUGGINGFACE_TOKEN=
HUGGINGFACE_REPO_ID=

# Email (Optional - for OTP)
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=
SMTP_PASSWORD=
SMTP_FROM_EMAIL=noreply@example.com

# Super Admin (Initial Setup)
# ⚠️ IMPORTANT: Change these credentials immediately after first login!
SUPER_ADMIN_EMAIL=admin@wisqu.com
SUPER_ADMIN_PASSWORD=ChangeMe123!
